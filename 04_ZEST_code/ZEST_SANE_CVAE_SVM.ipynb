{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ3XJYrMVka6"
      },
      "outputs": [],
      "source": [
        "pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n9dxgm12XDN4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "\n",
        "## inspired by VIT then include some libraries\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from einops import rearrange, reduce, repeat\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "from torchsummary import summary\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from numpy import load\n",
        "\n",
        "\n",
        "from tqdm import tqdm, trange\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrbogS3EV3Jg",
        "outputId": "4c8cc7a1-b28c-4b27-b877-5b07aa666e6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "# address of initial data\n",
        "CSV_SEQUENCES = \"/content/gdrive/MyDrive/Colab Notebooks/iot_device_classification/new_csv_sequences\"\n",
        "NPZ_WINDOWS = \"/content/gdrive/MyDrive/Colab Notebooks/iot_device_classification/npz_windows\"\n",
        "MODELS = \"/content/gdrive/MyDrive/Colab Notebooks/iot_device_classification/models\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2tjc8piiV9oj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f446c34-4a50-44bb-ec12-df9b0a1040e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  cuda (Tesla T4)\n"
          ]
        }
      ],
      "source": [
        "# check the availability of cuda\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "j5w6v1hNWVat"
      },
      "outputs": [],
      "source": [
        "def load_data_make_split(npz_file, train_percentage):\n",
        "    \"\"\"\n",
        "    Load training data (windows + one-hot labels) from compressed file. Split data into train and test set\n",
        "    Arguments:\n",
        "        - npz_file: The path to the *.npz file\n",
        "        - train_percentage: the percentage of data used for training (and not testing), e.g. 0.8\n",
        "    Returns:\n",
        "        A 4-tuple of train and test data with labels: (x_train, y_train, x_test, y_test)\n",
        "    \"\"\"\n",
        "    dict_data = load(npz_file)\n",
        "    x = dict_data['x']\n",
        "    y = dict_data['y']\n",
        "    train_length = int(len(x)*train_percentage)\n",
        "    x_train = x[:train_length]\n",
        "    y_train = y[:train_length]\n",
        "    x_test = x[train_length:]\n",
        "    y_test = y[train_length:]\n",
        "    return (x_train, y_train, x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRVVW5h2WVe2",
        "outputId": "f17682f7-d704-48be-c4e3-fc23bcc92599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train windws: (1071459, 200, 8)\n",
            "shape of train labels: (1071459, 1, 28)\n",
            "shape of test windows: (267865, 200, 8)\n",
            "shape of test labels: (267865, 1, 28)\n"
          ]
        }
      ],
      "source": [
        "# test load_data_make_split()\n",
        "x_train, y_train, x_test, y_test = load_data_make_split(\"{}/update_new_feature_all_days_all_devices.npz\".format(NPZ_WINDOWS), 0.8)\n",
        "print(\"shape of train windws: {}\".format(x_train.shape))\n",
        "print(\"shape of train labels: {}\".format(y_train.shape))\n",
        "print(\"shape of test windows: {}\".format(x_test.shape))\n",
        "print(\"shape of test labels: {}\".format(y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d2cUv0jzQu3",
        "outputId": "5b4149c5-f698-475b-bac9-9bfa3169012d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(24, 12041), (15, 12270), (6, 14034), (14, 15738), (2, 34720), (0, 36454), (27, 55804), (7, 61729), (1, 67218), (4, 68597), (10, 102906), (19, 111726), (22, 197876), (23, 228604), (5, 275855)]\n"
          ]
        }
      ],
      "source": [
        "## check number of devices in a dataset\n",
        "\n",
        "all_labels = []\n",
        "for i in range(len(y_train)):\n",
        "  index = np.where(y_train[i][0] == True)\n",
        "  k = index[0][0]\n",
        "  all_labels.append(k)\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  index = np.where(y_test[i][0] == True)\n",
        "  k = index[0][0]\n",
        "  all_labels.append(k)\n",
        "\n",
        "unique, count = np.unique(all_labels, return_counts = True)\n",
        "useable_data = []\n",
        "data_pair =dict()\n",
        "\n",
        "# select the devices data points > 10000 as the supervised pretraining data\n",
        "for i in range(len(unique)):\n",
        "  if count[i] > 10000:\n",
        "    useable_data.append(unique[i])\n",
        "    # print(unique[i], count[i])\n",
        "    data_pair[unique[i]] = count[i]\n",
        "sorted_data_by_counts = sorted(data_pair.items(), key=lambda x:x[1])\n",
        "print(sorted_data_by_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ljKJ4274hA3U"
      },
      "outputs": [],
      "source": [
        "all_device_names_dict = {0:'Smart Things', 1: 'Amazon Echo', 2:'Netatmo Welcome',3:'TP-Link Day Night Cloud camera', 4:'Samsung SmartCam', 5: 'Dropcam', 6: 'Withings Smart Baby Monitor', 7:'Belkin Wemo switch', 8:'TP-Link Smart plug',\n",
        "                         9: 'iHome', 10:'Belkin wemo motion sensor', 11:'NEST Protect smoke alarm', 12:'Netatmo weather station',13:'Withings Smart scale',14:'Withings Aura smart sleep sensor',15:'Light Bulbs LiFX Smart Bulb',\n",
        "                         16: 'Triby Speaker', 17:'PIX-STAR Photo-frame', 18 : 'HP Printer', 19: 'Samsung Galaxy Tab', 20: 'Nest Dropcam', 21:'Android Phone', 22:'Laptop', 23:'MacBook', 24:'Android Phone',\n",
        "                         25: 'IPhone', 26:'MacBook/Iphone', 27:'Insteon Camera'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fCSwBYs2jjOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe895c7e-b75c-43c7-80f8-b48d73b6562c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 4, 6, 10, 14, 15, 22, 24, 27]\n",
            "[5, 7]\n"
          ]
        }
      ],
      "source": [
        "## select the devices with enough amount of data a\n",
        "total_av_idx = [0, 1, 2, 4, 5, 6, 7, 10, 14, 15, 22, 24, 27]\n",
        "\n",
        "\n",
        "## random select 2 devices as unseen devices\n",
        "unseen_idx = random.sample(total_av_idx, 2)\n",
        "\n",
        "## the left will be seen devices\n",
        "seen_idx = [i for i in total_av_idx if i not in unseen_idx]\n",
        "\n",
        "print(seen_idx)\n",
        "print(unseen_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QAbrbpzazoDD"
      },
      "outputs": [],
      "source": [
        "num_unseen = len(unseen_idx)\n",
        "num_seen = len(seen_idx)\n",
        "\n",
        "\n",
        "# def one-hot index\n",
        "def idxtoOneHot(idx, length):\n",
        "  label_ohe = np.zeros((1,length))\n",
        "  label_ohe[0][idx] = 1\n",
        "  return label_ohe\n",
        "\n",
        "# def merge dictionary\n",
        "def Merge(dict1, dict2):\n",
        "  res = {**dict1, **dict2}\n",
        "  return res\n",
        "\n",
        "\n",
        "# def dictionary for unseen, seen, and name\n",
        "def generate_label_dict(unseen_idx, seed_idx):\n",
        "\n",
        "  \"\"\"\n",
        "    generate the label of each device and its corresponding name\n",
        "\n",
        "    like {9: 'iHome'}, we shuffle the data, 9 --> 10\n",
        "    the data will be  {'iHome': 10}\n",
        "\n",
        "    \"\"\"\n",
        "  unseen_dict = dict()\n",
        "  seen_dict = dict()\n",
        "  all_index_to_name = dict()\n",
        "  seen_index_to_name = dict()\n",
        "  unseen_index_to_name = dict()\n",
        "  for i in range(0,num_seen):\n",
        "    seen_dict[seen_idx[i]] = i\n",
        "    seen_index_to_name[i] = all_device_names_dict[seen_idx[i]]\n",
        "  for i in range(0,2):\n",
        "    unseen_dict[unseen_idx[i]] = num_seen + i\n",
        "    unseen_index_to_name[num_seen+i] = all_device_names_dict[unseen_idx[i]]\n",
        "  total_dict = Merge(unseen_dict, seen_dict)\n",
        "  all_index_to_name = Merge(seen_index_to_name, unseen_index_to_name)\n",
        "  return unseen_dict, seen_dict, total_dict,all_index_to_name\n",
        "\n",
        "## generate the training data\n",
        "def seen_training_data(init_x_train, init_x_test, init_y_train, init_y_test, seen_dict):\n",
        "  x_train_feature = []\n",
        "  y_train_feature = []\n",
        "  x_test_feature = []\n",
        "  y_test_feature = []\n",
        "\n",
        "  ## change from one-hot to label\n",
        "  for i in range(len(init_y_train)):\n",
        "    index = np.where(init_y_train[i][0] == True)\n",
        "    k = index[0][0]\n",
        "    if k in seen_idx:\n",
        "      x_train_feature.append(init_x_train[i])\n",
        "      # idx to new range\n",
        "      new_k = seen_dict[k]\n",
        "      y_train_feature.append(idxtoOneHot(new_k,len(seen_idx)))\n",
        "\n",
        "  for i in range(len(init_y_test)):\n",
        "    index = np.where(init_y_test[i][0] == True)\n",
        "    k = index[0][0]\n",
        "    if k in seen_idx:\n",
        "      x_test_feature.append(init_x_test[i])\n",
        "      # idx to new range\n",
        "      new_k = seen_dict[k]\n",
        "      y_test_feature.append(idxtoOneHot(new_k,len(seen_idx)))\n",
        "  return np.array(x_train_feature), np.array(y_train_feature), np.array(x_test_feature), np.array(y_test_feature)\n",
        "\n",
        "\n",
        "\n",
        "## extract features for the final test with both seen and unseen data\n",
        "def feature_extraction_data_seen_and_unseen(init_x_train, init_x_test, init_y_train, init_y_test, attr_dict):\n",
        "\n",
        "  x_train_attr = []\n",
        "  y_train_attr = []\n",
        "  x_test_attr = []\n",
        "  y_test_attr = []\n",
        "\n",
        "  attr_idx = [0,1,2,4,5,6,7,10,14,15,22,24,27]\n",
        "  for i in range(len(init_y_train)):\n",
        "    index = np.where(init_y_train[i][0] == True)\n",
        "    k = index[0][0]\n",
        "    if k in attr_idx:\n",
        "      x_train_attr.append(init_x_train[i])\n",
        "      # idx to new range\n",
        "      new_k = attr_dict[k]\n",
        "      y_train_attr.append(idxtoOneHot(new_k,len(attr_idx)))\n",
        "\n",
        "  for i in range(len(init_y_test)):\n",
        "    index = np.where(init_y_test[i][0] == True)\n",
        "    k = index[0][0]\n",
        "    if k in attr_idx:\n",
        "      x_test_attr.append(init_x_test[i])\n",
        "      # idx to new range\n",
        "      new_k = attr_dict[k]\n",
        "      y_test_attr.append(idxtoOneHot(new_k,len(attr_idx)))\n",
        "\n",
        "  x_train_attr = np.array(x_train_attr)\n",
        "  y_train_attr = np.array(y_train_attr)\n",
        "  x_test_attr = np.array(x_test_attr)\n",
        "  y_test_attr = np.array(y_test_attr)\n",
        "\n",
        "  return x_train_attr,  y_train_attr, x_test_attr, y_test_attr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dDc2DMvr0Axe"
      },
      "outputs": [],
      "source": [
        "unseen_dict, seen_dict,total_dict,all_index_to_name = generate_label_dict(unseen_idx, seen_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wOs2md-v0A5L"
      },
      "outputs": [],
      "source": [
        "x_train_feature, y_train_feature, x_test_feature, y_test_feature = seen_training_data(x_train, x_test, y_train, y_test, seen_dict)\n",
        "x_train_attr,  y_train_attr, x_test_attr, y_test_attr = feature_extraction_data_seen_and_unseen(x_train, x_test, y_train, y_test, total_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTh2GwVI0A7P",
        "outputId": "79ad6a5a-93bb-4472-dda2-3973f9ebd243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unseen dictionary {5: 11, 7: 12}\n",
            "seen dictionary {0: 0, 1: 1, 2: 2, 4: 3, 6: 4, 10: 5, 14: 6, 15: 7, 22: 8, 24: 9, 27: 10}\n",
            "total dictionary {5: 11, 7: 12, 0: 0, 1: 1, 2: 2, 4: 3, 6: 4, 10: 5, 14: 6, 15: 7, 22: 8, 24: 9, 27: 10}\n",
            "index to name dictionary {0: 'Smart Things', 1: 'Amazon Echo', 2: 'Netatmo Welcome', 3: 'Samsung SmartCam', 4: 'Withings Smart Baby Monitor', 5: 'Belkin wemo motion sensor', 6: 'Withings Aura smart sleep sensor', 7: 'Light Bulbs LiFX Smart Bulb', 8: 'Laptop', 9: 'Android Phone', 10: 'Insteon Camera', 11: 'Dropcam', 12: 'Belkin Wemo switch'}\n",
            "shape of train windws: (764405, 200, 8)\n",
            "shape of train labels: (764405, 1, 13)\n",
            "shape of test windows: (190837, 200, 8)\n",
            "shape of test labels: (190837, 1, 13)\n",
            "shape of train windws: (494250, 200, 8)\n",
            "shape of train labels: (494250, 1, 11)\n",
            "shape of test windows: (123408, 200, 8)\n",
            "shape of test labels: (123408, 1, 11)\n"
          ]
        }
      ],
      "source": [
        "print('unseen dictionary', unseen_dict)\n",
        "print('seen dictionary', seen_dict)\n",
        "print('total dictionary', total_dict)\n",
        "print('index to name dictionary', all_index_to_name)\n",
        "\n",
        "print(\"shape of train windws: {}\".format(x_train_attr.shape))\n",
        "print(\"shape of train labels: {}\".format(y_train_attr.shape))\n",
        "print(\"shape of test windows: {}\".format(x_test_attr.shape))\n",
        "print(\"shape of test labels: {}\".format(y_test_attr.shape))\n",
        "\n",
        "\n",
        "print(\"shape of train windws: {}\".format(x_train_feature.shape))\n",
        "print(\"shape of train labels: {}\".format(y_train_feature.shape))\n",
        "print(\"shape of test windows: {}\".format(x_test_feature.shape))\n",
        "print(\"shape of test labels: {}\".format(y_test_feature.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "EoBZ2IgQxIna"
      },
      "outputs": [],
      "source": [
        "\n",
        "### SANE model design\n",
        "\n",
        "\n",
        "\n",
        "# first conv2d to improve the performance\n",
        "class NetPatchEmbedding(nn.Module):\n",
        "    def __init__(self, in_channels: int = 1, feature_size: int = 200, emb_size: int = 8):\n",
        "        self.feature_szie = feature_size\n",
        "        super().__init__()\n",
        "        self.projection = nn.Sequential(\n",
        "            # using a linear one to map the input to emb_size\n",
        "            nn.Linear(emb_size, emb_size)\n",
        "        )\n",
        "        # sla_token: which aggrgate sequence level information\n",
        "        self.sla_token = nn.Parameter(torch.randn(1,1,emb_size))\n",
        "\n",
        "        # positional embedding : we let the model learn it, positional embedding is just a tensor of shape N_patchs\n",
        "        self.positions = nn.Parameter(torch.randn(feature_size + 1, emb_size) )\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        # print(x.shape)\n",
        "        b, _, _, = x.shape\n",
        "\n",
        "        x = self.projection(x)\n",
        "        # repeat sla_token to all the samples number b\n",
        "        sla_tokens = repeat(self.sla_token, '() n e -> b n e', b = b)\n",
        "\n",
        "        # then prepend the sla token to the input\n",
        "        x = torch.cat([sla_tokens, x], dim = 1)\n",
        "        # add positional embedding\n",
        "        x += self.positions\n",
        "\n",
        "        return x\n",
        "\n",
        "# NetPatchEmbedding()(k).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "sgtq0w5cz02O"
      },
      "outputs": [],
      "source": [
        "## self-attention mechanism\n",
        "\n",
        "class NetMultiHeadAttention(nn.Module):\n",
        "    def __init__(self, emb_size: int = 8, num_heads: int = 8, dropout: float = 0):\n",
        "        super().__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.num_heads = num_heads\n",
        "        ## calculate the Query key and value\n",
        "        self.keys = nn.Linear(emb_size, emb_size)\n",
        "        self.queries = nn.Linear(emb_size, emb_size)\n",
        "        self.values = nn.Linear(emb_size, emb_size)\n",
        "        self.att_drop = nn.Dropout(dropout)\n",
        "        self.projection = nn.Linear(emb_size, emb_size)\n",
        "\n",
        "    def forward(self, x : Tensor, mask: Tensor = None) -> Tensor:\n",
        "        # split keys, queries and values in num_heads\n",
        "        # the result query key and values has a shape of BATCH, HEADS, SEQUENCE_LEN, EMBEDDING_SIZE\n",
        "        queries = rearrange(self.queries(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        keys = rearrange(self.keys(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        values  = rearrange(self.values(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "\n",
        "        # sum up over the last axis   batch, num_heads, query_len, key_len\n",
        "        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys) # batch, num_heads, query_len, key_len\n",
        "        if mask is not None:\n",
        "            fill_value = torch.finfo(torch.float32).min\n",
        "            energy.mask_fill(~mask, fill_value)\n",
        "\n",
        "        scaling = self.emb_size ** (1/2)\n",
        "        att = F.softmax(energy, dim=-1) / scaling\n",
        "        att = self.att_drop(att)\n",
        "\n",
        "\n",
        "        # sum up over the third axis\n",
        "        out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n",
        "        out = rearrange(out, \"b h n d -> b n (h d)\")\n",
        "        out = self.projection(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "#add residual value\n",
        "class NetResidualAdd(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "      super().__init__()\n",
        "      self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "      res = x\n",
        "      x = self.fn(x, **kwargs)\n",
        "      x += res\n",
        "      return x\n",
        "\n",
        "\n",
        "class NetFeedForwardBlock(nn.Sequential):\n",
        "    def __init__(self, emb_size: int, expansion: int = 4, drop_p : float = 0.):\n",
        "      super().__init__(\n",
        "          nn.Linear(emb_size, expansion * emb_size),\n",
        "          nn.GELU(),\n",
        "          nn.Dropout(),\n",
        "          nn.Linear(expansion*emb_size, emb_size)\n",
        "      )\n",
        "\n",
        "class NetTransformerEncoderBlock(nn.Sequential):\n",
        "    def __init__(self,\n",
        "                 emb_size: int = 8,\n",
        "                 drop_p: float = 0.,\n",
        "                 forward_expansion: int = 4,\n",
        "                 forward_drop_p: float = 0.,\n",
        "                 ** kwargs):\n",
        "        super().__init__(\n",
        "            NetResidualAdd(nn.Sequential(\n",
        "                nn.LayerNorm(emb_size),\n",
        "                NetMultiHeadAttention(emb_size, **kwargs),\n",
        "                nn.Dropout(drop_p)\n",
        "            )),\n",
        "            NetResidualAdd(nn.Sequential(\n",
        "                nn.LayerNorm(emb_size),\n",
        "                NetFeedForwardBlock(\n",
        "                    emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n",
        "                nn.Dropout(drop_p)\n",
        "            )\n",
        "            ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "KxggFso_0q1t"
      },
      "outputs": [],
      "source": [
        "\n",
        "## adding multiple encoders if needed\n",
        "class NetTransformerEncoder(nn.Sequential):\n",
        "    def __init__(self, depth: int = 2, **kwargs):\n",
        "        super().__init__(*[NetTransformerEncoderBlock(**kwargs) for _ in range(depth)])\n",
        "\n",
        "## classification head for classification\n",
        "class NetClassificationHead(nn.Sequential):\n",
        "    def __init__(self, emb_size: int = 8, n_classes: int = 11, n_attr = 3, n_extract = 20):\n",
        "        super().__init__(\n",
        "            Reduce('b n e -> b e', reduction='mean'),\n",
        "            nn.LayerNorm(emb_size),\n",
        "            # add one layer for feature extraction\n",
        "            nn.Linear(emb_size, n_extract),\n",
        "\n",
        "            # add one more layer for attribute extraction\n",
        "            nn.Linear(n_extract, n_attr),\n",
        "            nn.Linear(n_attr, n_classes))\n",
        "\n",
        "##\n",
        "class NetFormer(nn.Sequential):\n",
        "    def __init__(self,\n",
        "                in_channels: int = 1,\n",
        "                feature_size: int = 200,\n",
        "                emb_size: int = 8,\n",
        "                depth: int = 2,\n",
        "                n_classes: int = 11,\n",
        "                n_attr = 3,\n",
        "                n_extract = 20,\n",
        "                **kwargs):\n",
        "        super().__init__(\n",
        "            NetPatchEmbedding(in_channels, feature_size, emb_size,),\n",
        "            NetTransformerEncoder(depth, emb_size=emb_size, **kwargs),\n",
        "            NetClassificationHead(emb_size, n_classes, n_attr)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlpAeKn60q4_"
      },
      "outputs": [],
      "source": [
        "summary(NetFormer(), (200,8), device='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "pGrtxr5DsyA-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# change label from one-hot to integer\n",
        "y_train_labels = []\n",
        "y_test_labels = []\n",
        "for i in range(len(y_train_feature)):\n",
        "  index = np.where(y_train_feature[i][0] == True)\n",
        "  k = index[0][0]\n",
        "  y_train_labels.append(k)\n",
        "\n",
        "for i in range(len(y_test_feature)):\n",
        "  index = np.where(y_test_feature[i][0] == True)\n",
        "  k = index[0][0]\n",
        "  y_test_labels.append(k)\n",
        "\n",
        "\n",
        "# print(y_train_labels[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "ZV7jIFPPtOM9"
      },
      "outputs": [],
      "source": [
        "model = NetFormer().to(device)\n",
        "N_EPOCHS = 30\n",
        "LR = 0.0005\n",
        "\n",
        "## reshape the input to feed into ZEST model\n",
        "x_train = x_train_feature.reshape((-1,200,8))\n",
        "x_test = x_test_feature.reshape((-1,200,8))\n",
        "\n",
        "x_train = torch.tensor(x_train)\n",
        "y_train = torch.tensor(y_train_labels)\n",
        "x_test = torch.tensor(x_test)\n",
        "y_test = torch.tensor(y_test_labels)\n",
        "# print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSyk3PWgFqHI",
        "outputId": "62daeef5-93d1-4273-840a-e51c501a5f47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  cuda (Tesla T4)\n"
          ]
        }
      ],
      "source": [
        "## put the data into torch data loader\n",
        "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(x_test, y_test)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
        "# print(summary(NetFormer(), (8, 200), device = 'cuda'))\n",
        "# print(x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "5usp0_0mTOuO"
      },
      "outputs": [],
      "source": [
        "## define 2 set to store the results for figure plots\n",
        "\n",
        "acc_train_set = []\n",
        "acc_test_set = []\n",
        "\n",
        "loss_train_set = []\n",
        "loss_test_set = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enhCrZOWFqLU"
      },
      "outputs": [],
      "source": [
        "## train the model\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=LR)\n",
        "criterion = CrossEntropyLoss()\n",
        "for epoch in trange(N_EPOCHS, desc=\"Training\"):\n",
        "  train_loss = 0.0\n",
        "  correct, total = 0, 0\n",
        "  for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1} in training\", leave=True,  mininterval=50, miniters=50):\n",
        "    x, y = batch\n",
        "    # print('shape of x :',x.shape)\n",
        "    # print('shape of y :',y.shape)\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    y_hat = model(x)\n",
        "    # y_hat = y_hat.reshape((-1,1,28))\n",
        "    # print('shape of y_hat', y_hat.shape)\n",
        "    loss = criterion(y_hat, y)\n",
        "\n",
        "    train_loss += loss.detach().cpu().item() / len(train_dataloader)\n",
        "    correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
        "    total += len(x)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {train_loss:.2f}\")\n",
        "  print(f\"Epoch {epoch + 1}/{N_EPOCHS} Training accuracy: {correct / total * 100:.2f}%\")\n",
        "  acc_train_set.append(correct / total)\n",
        "  loss_train_set.append(train_loss)\n",
        "  # Test loop\n",
        "  with torch.no_grad():\n",
        "    correct, total = 0, 0\n",
        "    test_loss = 0.0\n",
        "    for batch in tqdm(test_dataloader, desc=\"Testing\", leave=True, mininterval=5, miniters=10):\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        y_hat = model(x)\n",
        "        loss = criterion(y_hat, y)\n",
        "        test_loss += loss.detach().cpu().item() / len(test_dataloader)\n",
        "\n",
        "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
        "        total += len(x)\n",
        "    print(f\"Test loss: {test_loss:.2f}\")\n",
        "    print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
        "    acc_test_set.append(correct / total)\n",
        "    loss_test_set.append(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OlD2XG4q6tq"
      },
      "outputs": [],
      "source": [
        "print(acc_train_set)\n",
        "print(acc_test_set)\n",
        "print(loss_train_set)\n",
        "print(loss_test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "vuDiMqYcTplG",
        "outputId": "d881e005-c294-4994-b30d-1161ea3acf9a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# draw training progress\n",
        "x = np.linspace(1,25,25)\n",
        "plt.plot(x,acc_train_set)\n",
        "plt.plot(x,acc_test_set)\n",
        "plt.title('Transformer training progress')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "RYBe3eJUTpuT",
        "outputId": "55438345-91e4-49c4-898f-15c02e372445"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# draw training progress of loss\n",
        "x = np.linspace(1,25,25)\n",
        "plt.plot(x,loss_train_set)\n",
        "plt.plot(x,loss_test_set)\n",
        "plt.title('Transformer training progress')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "JnrG-TlOrqFG"
      },
      "outputs": [],
      "source": [
        "## save the model\n",
        "torch.save(model.state_dict(), \"{}/ZEST_0.pt\".format(MODELS))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_IY202TwKRU",
        "outputId": "05d50d88-0305-4d9d-f31c-3b941aea2488"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "## load the saved model\n",
        "model.load_state_dict(torch.load(\"{}/ZEST_0.pt\".format(MODELS)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "DazdEFzWXEh8"
      },
      "outputs": [],
      "source": [
        "\n",
        "## combine the data to get the attributes for all the devices : seen and unseen\n",
        "## !! just based on the model trained only on seen classes\n",
        "new_x = np.concatenate((x_train_attr,x_test_attr))\n",
        "new_y = np.concatenate((y_train_attr,y_test_attr))\n",
        "\n",
        "\n",
        "y_train_attr = []\n",
        "for i in range(len(new_y)):\n",
        "  index = np.where(new_y[i][0] == True)\n",
        "  k = index[0][0]\n",
        "  y_train_attr.append(k)\n",
        "\n",
        "\n",
        "new_x = new_x.reshape((-1,200,8))\n",
        "\n",
        "new_x_train = torch.tensor(new_x)\n",
        "new_y_train = torch.tensor(y_train_attr)\n",
        "\n",
        "\n",
        "new_train_dataset = torch.utils.data.TensorDataset(new_x_train, new_y_train)\n",
        "new_train_dataloader = torch.utils.data.DataLoader(new_train_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iayvivg9YIyq"
      },
      "outputs": [],
      "source": [
        "## take the output of 2 layers to work as two level of features L and Lambda we mentioned in the paper\n",
        "\n",
        "features_in_hook = []\n",
        "features_out_hook = []\n",
        "\n",
        "attr_in_hook = []\n",
        "attr_out_hook = []\n",
        "\n",
        "\n",
        "\n",
        "## define 2 hook to get the output of certain layer in the model\n",
        "\n",
        "def feature_hook(module, fea_in, fea_out):\n",
        "    features_in_hook.append(fea_in)\n",
        "    features_out_hook.append(fea_out)\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "def attr_hook(module, attr_in, attr_out):\n",
        "    attr_in_hook.append(attr_in)\n",
        "    attr_out_hook.append(attr_out)\n",
        "    return None\n",
        "\n",
        "net = model\n",
        "\n",
        "feature_layer_name = '2.2'\n",
        "attr_layer_name = '2.3'\n",
        "for (name, module) in net.named_modules():\n",
        "  # print(name)\n",
        "  if name == feature_layer_name:\n",
        "    module.register_forward_hook(hook=feature_hook)\n",
        "  elif name == attr_layer_name:\n",
        "    module.register_forward_hook(hook=attr_hook)\n",
        "\n",
        "\n",
        "prediction = []\n",
        "real = []\n",
        "with torch.no_grad():\n",
        "  correct, total = 0, 0\n",
        "  test_loss = 0.0\n",
        "  for batch in tqdm(new_train_dataloader, desc=\"Testing\"):\n",
        "    x, y = batch\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    y_hat = net(x)\n",
        "    for i in y:\n",
        "      real.append(i)\n",
        "    prediction.append(y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT26m0-QDVKb",
        "outputId": "43c2a2c4-59ae-469a-8088-63b14978e113"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(955242,)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "real_label = []\n",
        "for j in range(len(real)):\n",
        "  real_label.append(real[j].cpu().numpy())\n",
        "real_label = np.array(real_label)\n",
        "real_label.shape\n",
        "\n",
        "# print(features_out_hook[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "gOODhXlg8T28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8160a81-f1eb-4abd-f9ea-8429693c43cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(955242, 20)\n",
            "(955242, 3)\n"
          ]
        }
      ],
      "source": [
        "new_feature = []\n",
        "for i in range(len(features_out_hook)):\n",
        "  for j in range(len(features_out_hook[i])):\n",
        "    new_feature.append(features_out_hook[i][j].cpu().numpy())\n",
        "\n",
        "new_attr = []\n",
        "for i in range(len(attr_out_hook)):\n",
        "  for j in range(len(attr_out_hook[i])):\n",
        "    new_attr.append(attr_out_hook[i][j].cpu().numpy())\n",
        "\n",
        "new_feature =np.array(new_feature)\n",
        "new_attr =np.array(new_attr)\n",
        "print(new_feature.shape)\n",
        "print(new_attr.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T43OoZQPfFD0",
        "outputId": "141847f6-93a1-42c9-94f7-7efdc4c55d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 11: [], 12: []}\n",
            "{0: array([-18.469843,  23.125456, -10.08955 ], dtype=float32), 1: array([-10.145199 ,   3.885353 ,   5.9235253], dtype=float32), 2: array([-10.400902 ,  -2.385714 ,  -6.9343824], dtype=float32), 3: array([  3.25472 , -18.290081,  14.812773], dtype=float32), 4: array([ 3.8146322, 17.679535 , -8.597265 ], dtype=float32), 5: array([ 6.0684156, -5.3204083, -4.1698313], dtype=float32), 6: array([15.771193 ,  8.869213 ,  6.5278664], dtype=float32), 7: array([ 6.2723093, -2.2644265,  7.1916623], dtype=float32), 8: array([-15.127081 , -11.50587  ,  -1.3410503], dtype=float32), 9: array([-15.7846365,  -9.107595 ,  -2.739224 ], dtype=float32), 10: array([ 4.6775136,  3.3596647, 16.00385  ], dtype=float32), 11: array([-15.58578 ,  14.876772,  -5.219828], dtype=float32), 12: array([ 7.326816, -4.766336, -3.980715], dtype=float32)}\n"
          ]
        }
      ],
      "source": [
        "attr_dict = dict()\n",
        "for i in range(13):\n",
        "  attr_dict[i] = []\n",
        "print(attr_dict)\n",
        "\n",
        "\n",
        "for i in range(len(real_label)):\n",
        "  k = real_label[i]\n",
        "  # print(k)\n",
        "  attr_dict[k].append(new_attr[i])\n",
        "\n",
        "\n",
        "## get the attribute vector for each devices\n",
        "attr_lib = dict()\n",
        "for key in attr_dict:\n",
        "  # print(key)\n",
        "  attr_lib[key] = np.mean(attr_dict[key],axis = 0)\n",
        "print(attr_lib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbRJDnEjf45y",
        "outputId": "92fc052a-fa76-428c-9949-8628880c3db7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23.125456\n",
            "-18.469843\n",
            "{0: [0.0, 1.0, 0.2], 1: [0.2, 0.54, 0.59], 2: [0.19, 0.39, 0.28], 3: [0.52, 0.0, 0.8], 4: [0.54, 0.87, 0.24], 5: [0.59, 0.32, 0.34], 6: [0.82, 0.66, 0.6], 7: [0.59, 0.39, 0.62], 8: [0.08, 0.17, 0.41], 9: [0.06, 0.23, 0.38], 10: [0.56, 0.52, 0.83], 11: [0.07, 0.8, 0.32], 12: [0.62, 0.33, 0.35]}\n"
          ]
        }
      ],
      "source": [
        "## normalize the attributes from 0-1\n",
        "max_for_all = []\n",
        "min_for_all = []\n",
        "for i in attr_lib.keys():\n",
        "  k = np.max(attr_lib[i])\n",
        "  max_for_all.append(k)\n",
        "  l = np.min(attr_lib[i])\n",
        "  min_for_all.append(l)\n",
        "\n",
        "\n",
        "maxi = np.max(max_for_all)\n",
        "mini = np.min(min_for_all)\n",
        "\n",
        "print(maxi)\n",
        "print(mini)\n",
        "\n",
        "\n",
        "def transfer_new_attr(mean, maxi, mini):\n",
        "  new = []\n",
        "  for i in range(len(mean)):\n",
        "    x_scale = 1 * ((mean[i] - mini) / (maxi-mini))\n",
        "    new.append(np.round(x_scale,2))\n",
        "  return new\n",
        "\n",
        "new_attr_lib = dict()\n",
        "for key in attr_lib:\n",
        "  new_attr_lib[key] = transfer_new_attr(attr_lib[key],maxi, mini)\n",
        "\n",
        "new_attr_set = []\n",
        "new_y_label = []\n",
        "for i in range(len(real_label)):\n",
        "    k = real_label[i]\n",
        "    new_y_label.append(k)\n",
        "    new_attr_set.append(new_attr_lib[k])\n",
        "\n",
        "print(new_attr_lib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUA5mj-bl57u"
      },
      "outputs": [],
      "source": [
        "seen_index = [0,1,2,3,4,5,6,7,8,9,10]\n",
        "unseen_index = [11,12]\n",
        "print(new_attr_lib)\n",
        "seen_num = len(seen_index)\n",
        "unseen_num = len(unseen_index)\n",
        "attr_num = 3\n",
        "\n",
        "#def attribute to name\n",
        "attr_lib_name = dict()\n",
        "for i in range(13):\n",
        "  attr_lib_name[all_index_to_name[i]] = new_attr_lib[i]\n",
        "attr_lib_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "cgyOPjflzP2g"
      },
      "outputs": [],
      "source": [
        "seen_class_label = []\n",
        "seen_class_attr = []\n",
        "seen_class_features = []\n",
        "\n",
        "unseen_class_label = []\n",
        "unseen_class_attr  = []\n",
        "unseen_class_features  = []\n",
        "\n",
        "\n",
        "# save the 2 level features and attributes for CVAE model to learn\n",
        "# the mapping between them\n",
        "for i in range(len(real_label)):\n",
        "  if real_label[i] in seen_index:\n",
        "    seen_class_label.append(real_label[i])\n",
        "    seen_class_attr.append(new_attr[i])\n",
        "    seen_class_features.append(new_feature[i])\n",
        "  elif real_label[i] in unseen_index:\n",
        "    unseen_class_label.append(real_label[i])\n",
        "    unseen_class_attr.append(new_attr[i])\n",
        "    unseen_class_features.append(new_feature[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IemZjl5l5fjX",
        "outputId": "b47ac020-839f-434c-96bb-4aa3d9bf08f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({8: 197876, 5: 102906, 3: 68597, 1: 67218, 10: 55804, 0: 36454, 2: 34720, 6: 15738, 4: 14034, 7: 12270, 9: 12041})\n",
            "Counter({11: 275855, 12: 61729})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "print(Counter(seen_class_label))\n",
        "print(Counter(unseen_class_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF85F9eGzP47",
        "outputId": "c425a26c-a52a-4339-d1b7-528eb88d66d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 2 3\n"
          ]
        }
      ],
      "source": [
        "## save the data with features, attributes, and labels\n",
        "\n",
        "from numpy import savez_compressed\n",
        "from datetime import date\n",
        "\n",
        "today = date.today()\n",
        "seen_num = len(seen_idx)\n",
        "unseen_num = len(unseen_idx)\n",
        "attr_num = len(seen_class_attr[0])\n",
        "print(seen_num, unseen_num, attr_num)\n",
        "\n",
        "\n",
        "npz_file_seen = \"{}/test_2_5_24_{}_seen_classes_{}_new_attribute_{}\".format(NPZ_WINDOWS,seen_num, attr_num, today)\n",
        "savez_compressed(npz_file_seen, x = seen_class_features, y = seen_class_label, attribute = seen_class_attr)\n",
        "\n",
        "npz_file_unseen = \"{}/test_2_5_24_{}_unseen_{}_new_attribute_{}\".format(NPZ_WINDOWS,unseen_num, attr_num,today)\n",
        "savez_compressed(npz_file_unseen, x = unseen_class_features, y = unseen_class_label, attribute = unseen_class_attr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "eWmpwF6Oml-8"
      },
      "outputs": [],
      "source": [
        "def load_data_make_split(npz_file, train_percentage, attr_dimension):\n",
        "    \"\"\"\n",
        "    Load training data (windows + one-hot labels) from compressed file. Split data into train and test set\n",
        "\n",
        "    Arguments:\n",
        "        - npz_file: The path to the *.npz file\n",
        "        - train_percentage: the percentage of data used for training (and not testing), e.g. 0.8\n",
        "    Returns:\n",
        "        A 4-tuple of train and test data with labels: (x_train, y_train, x_test, y_test)\n",
        "    \"\"\"\n",
        "    dict_data = load(npz_file)\n",
        "    x = dict_data['x']\n",
        "    x = x.reshape((x.shape[0],20))\n",
        "    y = dict_data['y']\n",
        "    z = dict_data['attribute']\n",
        "    z = z.reshape((z.shape[0],attr_dimension))\n",
        "\n",
        "    train_length = int(len(x)*train_percentage)\n",
        "    x_train = x[:train_length]\n",
        "    y_train = y[:train_length]\n",
        "    z_train = z[:train_length]\n",
        "    x_test = x[train_length:]\n",
        "    y_test = y[train_length:]\n",
        "    z_test = z[train_length:]\n",
        "\n",
        "    return (x_train, y_train, z_train, x_test, y_test, z_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPBEl_Tqd8Hv"
      },
      "outputs": [],
      "source": [
        "#### define the CVAE model for learning the mapping between Data space and Attributes space\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout, Reshape\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Input\n",
        "from collections import Counter\n",
        "from numpy import savez_compressed\n",
        "from datetime import date\n",
        "from numpy import load\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout, Reshape, Lambda, Input, BatchNormalization, concatenate\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import svm\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import svm\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "\n",
        "attr_num = 3\n",
        "seen_num = 11\n",
        "unseen_num = 2\n",
        "\n",
        "x_train, y_train, z_train, x_test, y_test, z_test = load_data_make_split(\"{}.npz\".format(npz_file_seen),0.8, attr_num )\n",
        "real_train_x, real_train_y, real_train_z, real_test_x, real_test_y, real_test_z  =  load_data_make_split(\"{}.npz\".format(npz_file_unseen), 0.8,attr_num )\n",
        "\n",
        "# reshape the label to be onehot form\n",
        "labels_ohe= np.empty((y_train.shape[0],seen_num,1), dtype=np.float32)\n",
        "for i in range(y_train.shape[0]):\n",
        "  label_ohe = np.zeros((1,seen_num))\n",
        "  label_ohe[0][int(y_train[i])] = 1\n",
        "  labels_ohe[i] = label_ohe.T\n",
        "\n",
        "labels_ohe_test= np.empty((y_test.shape[0], seen_num, 1), dtype=np.float32)\n",
        "for i in range(y_test.shape[0]):\n",
        "  label_ohe = np.zeros((1,seen_num))\n",
        "  label_ohe[0][int(y_test[i])] = 1\n",
        "  labels_ohe_test[i] = label_ohe.T\n",
        "\n",
        "y_train = labels_ohe.reshape((y_train.shape[0],-1))\n",
        "y_test = labels_ohe_test.reshape((y_test.shape[0],-1))\n",
        "\n",
        "disable_eager_execution()\n",
        "\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 64\n",
        "test_size = x_test.shape[0]\n",
        "\n",
        "\n",
        "m = 64 # bacthsize\n",
        "n_x = 20 # feature dimension\n",
        "n_y = attr_num  # attribute vector\n",
        "n_z = 4  # noise dimension\n",
        "interNo = n_x  # number of neurons in the middle layer\n",
        "n_epoch = 10  # number of epoches\n",
        "\n",
        "# encoder input dimension\n",
        "input_ic = Input(shape=[n_x+n_y], name = 'img_class' )\n",
        "# attribute vector\n",
        "cond  = Input(shape=[n_y] , name='class')\n",
        "temp_h_q = Dense(interNo, activation='relu')(input_ic)\n",
        "h_q_zd = Dropout(rate=0.2)(temp_h_q)\n",
        "h_q = Dense(interNo, activation='relu')(h_q_zd)\n",
        "# dense layer for mu\n",
        "temp_h_q_2 = Dense(n_z, activation='linear')(h_q)\n",
        "mu = Dense(n_z, activation='linear')(temp_h_q_2)\n",
        "# dense layer for log\n",
        "# log_sigma = Dense(n_z, activation='linear')(h_q)\n",
        "log_sigma = Dense(n_z, activation='linear')(temp_h_q_2)\n",
        "\n",
        "def sample_z(args):\n",
        "    mu, log_sigma = args\n",
        "    eps = tf.random.normal(shape=[n_z], mean=0., stddev=1.)\n",
        "    return mu + tf.exp(log_sigma / 2) * eps\n",
        "\n",
        "z = Lambda(sample_z)([mu, log_sigma])\n",
        "\n",
        "# Depending on the keras version...\n",
        "# z_cond = merge([z, cond] , mode='concat', concat_axis=1)\n",
        "z_cond = concatenate([z, cond])\n",
        "\n",
        "decoder_hidden = Dense(32, activation='relu')\n",
        "decoder_out = Dense(n_x, activation='linear')\n",
        "h_p = decoder_hidden(z_cond)\n",
        "reconstr = decoder_out(h_p)\n",
        "vae = Model(inputs=[input_ic , cond], outputs=[reconstr])\n",
        "\n",
        "encoder = Model(inputs=[input_ic , cond], outputs=[mu])\n",
        "\n",
        "\n",
        "d_in = Input(shape=[n_z+n_y])\n",
        "d_h = decoder_hidden(d_in)\n",
        "d_out = decoder_out(d_h)\n",
        "decoder = Model(d_in, d_out)\n",
        "\n",
        "def vae_loss(y_true, y_pred):\n",
        "    \"\"\" Calculate loss = reconstruction loss + KL loss for each data in minibatch \"\"\"\n",
        "    # E[log P(X|z)]\n",
        "    recon = tf.keras.backend.mean(tf.keras.backend.square(y_pred - y_true), axis=1)\n",
        "    # D_KL(Q(z|X) || P(z|X)); calculate in closed form as both dist. are Gaussian\n",
        "    kl = 0.5 * tf.keras.backend.sum(tf.exp(log_sigma) + tf.keras.backend.square(mu) - 1. - log_sigma, axis=1)\n",
        "    #print 'kl : ' + str(kl)\n",
        "    return recon + kl\n",
        "\n",
        "encoder.summary()\n",
        "decoder.summary()\n",
        "vae.compile(optimizer=\"adam\", loss=vae_loss)\n",
        "\n",
        "\n",
        "X_train = np.concatenate([x_train , z_train], axis=1)\n",
        "print(X_train.shape)\n",
        "print ('Fitting VAE Model...')\n",
        "vae.fit({'img_class' : X_train , 'class' : z_train}, x_train, batch_size=m, epochs=n_epoch)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_reconstruction_loss(x_train, y_train, z_train, encoder, decoder, flag):\n",
        "\n",
        "  diff_set = dict()\n",
        "  sess = tf.compat.v1.Session()\n",
        "\n",
        "  for i in range(200):\n",
        "    a = x_train[i]\n",
        "    # flag = 0 seen flag = 1 unseen\n",
        "    if flag == 0:\n",
        "      b_1 = y_train[i]\n",
        "      for j in range(len(b_1)):\n",
        "        if b_1[j] == 1:\n",
        "          b = j\n",
        "    else:\n",
        "      b =  y_train[i]\n",
        "    c = z_train[i]\n",
        "    # print(a, b, c)\n",
        "    enc_ip = np.concatenate((a, c))\n",
        "    # print(enc_ip.shape)\n",
        "    latent = encoder.predict([[enc_ip],[c] ])\n",
        "    latent = latent.reshape((1,-1))\n",
        "    c = c.reshape((1,-1))\n",
        "\n",
        "    dec_ip = np.concatenate((latent, c) , axis=1)\n",
        "    pseudoTrainData_test = decoder.predict(dec_ip)\n",
        "    with sess.as_default():\n",
        "      diff =tf.keras.backend.mean(tf.keras.backend.square(pseudoTrainData_test- a), axis=1).eval()\n",
        "    if b not in diff_set.keys():\n",
        "      diff_set[b] = diff\n",
        "    else:\n",
        "      before = diff_set[b]\n",
        "      after = np.concatenate((before,diff))\n",
        "      diff_set[b] = after\n",
        "  for i in diff_set.keys():\n",
        "    print('mean of {} : {} '.format(i,np.mean(diff_set[i])))\n",
        "\n",
        "  return diff_set\n",
        "\n",
        "\n",
        "diff_set_seen = generate_reconstruction_loss(x_train, y_train, z_train, encoder, decoder, flag = 0)\n",
        "diff_set_unseen = generate_reconstruction_loss(real_train_x, real_train_y, real_train_z, encoder, decoder, flag = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0-556RDlZhK"
      },
      "outputs": [],
      "source": [
        "### generate pseudo data for all the classes\n",
        "\n",
        "def generate_pseudo_data(nSamples, label, attr_lib,noise_gen):\n",
        "  attr = attr_lib[label]\n",
        "  pseudoTrainData = []\n",
        "  pseudoTrainLabels =[]\n",
        "  pseudoTrainAttr = []\n",
        "  for i in range(0,nSamples):\n",
        "    pseudoTrainLabels.append(label)\n",
        "    pseudoTrainAttr.append(attr)\n",
        "  pseudoTrainAttr = np.array(pseudoTrainAttr)\n",
        "  pseudoTrainLabels = np.array(pseudoTrainLabels)\n",
        "  dec_ip = np.concatenate((noise_gen, pseudoTrainAttr) , axis=1)\n",
        "  pseudoTrainData = decoder.predict(dec_ip)\n",
        "  return pseudoTrainData, pseudoTrainLabels\n",
        "\n",
        "\n",
        "\n",
        "def generating_pesudo_all_data(attr_lib):\n",
        "  nSamples = 100000\n",
        "  totalExs = nSamples\n",
        "  sess = tf.compat.v1.Session()\n",
        "  with sess.as_default():\n",
        "    noise_gen = K.random_normal(shape=(totalExs, n_z), mean=0., stddev=1.).eval()\n",
        "\n",
        "  total_pseudo_data = []\n",
        "  total_pseudo_label = []\n",
        "  for i in range(0,13):\n",
        "    print('Generating Pseudo Data for class {}....... '.format(i))\n",
        "    data_1, labels_1 = generate_pseudo_data(nSamples,i, attr_lib, noise_gen)\n",
        "    if i == 0:\n",
        "      total_pseudo_data = data_1\n",
        "      total_pseudo_label = labels_1\n",
        "    else:\n",
        "      total_pseudo_data = np.concatenate((total_pseudo_data, data_1))\n",
        "      total_pseudo_label = np.concatenate((total_pseudo_label, labels_1))\n",
        "  # reshape the data\n",
        "  total_pseudo_label = total_pseudo_label.reshape((-1,))\n",
        "\n",
        "  return total_pseudo_data, total_pseudo_label\n",
        "\n",
        "\n",
        "\n",
        "svm_train_data, svm_train_label = generating_pesudo_all_data(attr_lib)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njzN6xKYlZjo"
      },
      "outputs": [],
      "source": [
        "\n",
        "## training a supervised classifier based on the pesudo data generated\n",
        "print ('Training SVM-100')\n",
        "clf5 = svm.SVC(C=100)\n",
        "clf5.fit(svm_train_data, svm_train_label)\n",
        "\n",
        "\n",
        "\n",
        "x_train, y_train, z_train, x_test, y_test, z_test = load_data_make_split(\"{}.npz\".format(npz_file_seen),0.8, attr_num )\n",
        "final_train_x = np.concatenate((real_train_x,x_test),axis = 0)\n",
        "print(final_train_x.shape)\n",
        "final_train_y = np.concatenate((real_train_y,y_test),axis = 0)\n",
        "print(final_train_y.shape)\n",
        "\n",
        "\n",
        "print ('Predicting ZSL....')\n",
        "pred_zsl = clf5.predict(real_train_x)\n",
        "print(np.unique(pred_zsl))\n",
        "print (accuracy_score(real_train_y , pred_zsl))\n",
        "\n",
        "\n",
        "print ('Predicting GZSL...')\n",
        "pred_gzsl = clf5.predict(final_train_x)\n",
        "print(np.unique(pred_gzsl))\n",
        "print (accuracy_score(final_train_y , pred_gzsl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "iiQwHssUlZtH"
      },
      "outputs": [],
      "source": [
        "## show the accuracy for each class\n",
        "\n",
        "def accuracy_for_each_class(real_train_y, pred_zsl):\n",
        "\n",
        "  data_pair =dict()\n",
        "  unique, count = np.unique(real_train_y, return_counts = True)\n",
        "  for i in range(len(unique)):\n",
        "    data_pair[unique[i]] = count[i]\n",
        "    print(unique[i], count[i])\n",
        "  print(data_pair)\n",
        "\n",
        "  count_all = dict()\n",
        "\n",
        "  for i in range(len(real_train_y)):\n",
        "    b = real_train_y[i]\n",
        "    if b not in count_all.keys():\n",
        "      if pred_zsl[i] == real_train_y[i]:\n",
        "        count_all[b] = 1\n",
        "      # else:\n",
        "        # print('real : {}, predict : {}'.format(real_train_y[i],pred_zsl[i]))\n",
        "    else:\n",
        "      if pred_zsl[i] == real_train_y[i]:\n",
        "        before = count_all[b]\n",
        "        after = before + 1\n",
        "        count_all[b] = after\n",
        "      # else:\n",
        "      #   print('real : {}, predict : {}'.format(real_train_y[i],pred_zsl[i]))\n",
        "\n",
        "  print(count_all)\n",
        "\n",
        "  acc = dict()\n",
        "  for i in data_pair.keys():\n",
        "    acc[all_index_to_name[i]] = count_all[i]/data_pair[i]\n",
        "  print(acc)\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83qXkS77lZv2"
      },
      "outputs": [],
      "source": [
        "acc_zsl  = accuracy_for_each_class(real_train_y, pred_zsl)\n",
        "acc_gzsl  = accuracy_for_each_class(final_train_y, pred_gzsl)\n",
        "\n",
        "print(acc_zsl)\n",
        "print(acc_gzsl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUcT1q1JlYi1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVvEox0TlYk5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VEov4NalYm5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3lIjhZTlYqF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piBPDW3bWwxS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btCvFscWWwzB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaq-q1K4Ww1O"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
